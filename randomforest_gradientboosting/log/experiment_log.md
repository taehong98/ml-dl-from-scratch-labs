# Experiment Log

## Hypothesis
- μ λ°©μ•” λ°μ΄ν„°μ…‹μ—μ„ **Random Forest**μ™€ **Gradient Boosting**μ€ λ¨λ‘ λ†’μ€ μ •ν™•λ„λ¥Ό λ³΄μ΄μ§€λ§,
  ν•™μµ λ°©μ‹ μ°¨μ΄(λ°°κΉ… vs λ¶€μ¤ν…)λ΅ μΈν•΄ **μ •ν™•λ„μ™€ μ¤‘μ” νΉμ„±(Top-5 feature)**μ΄ λ‹¤λ¥΄κ² λ‚νƒ€λ‚  μ μλ‹¤.
- νΉν Boostingμ€ μμ°¨μ μΌλ΅ μ¤μ°¨λ¥Ό λ³΄μ •ν•λ―€λ΅, κ°™μ€ λ°μ΄ν„°μ—μ„λ„ μ¤‘μ”ν•κ² λ³΄λ” νΉμ„±μ΄ Random Forestμ™€ μΌλ¶€ λ‹¬λΌμ§ μ μλ‹¤.

## Setup
- **Dataset**
  - `sklearn.datasets.load_breast_cancer`
  - Features: `data.feature_names` (μ—°μ†ν• νΉμ„±λ“¤)
  - Target: `data.target` (μ΄μ§„ λ¶„λ¥)
- **Split**
  - `train_test_split(test_size=0.2, random_state=42)`
- **Models**
  - `RandomForestClassifier()` (κΈ°λ³Έ ν•μ΄νΌνλΌλ―Έν„°)
  - `GradientBoostingClassifier()` (κΈ°λ³Έ ν•μ΄νΌνλΌλ―Έν„°)
- **Metric**
  - Accuracy (`sklearn.metrics.accuracy_score`)
- **Analysis / Visualization**
  - κ° λ¨λΈμ `feature_importances_` μ¶”μ¶
  - μ¤‘μ”λ„ λ‚΄λ¦Όμ°¨μ μ •λ ¬ ν›„ **μƒμ„ 5κ°** μΈλ±μ¤ μ„ νƒ
  - `seaborn.barplot`μΌλ΅ Top-5 μ¤‘μ” νΉμ„± μ‹κ°ν™”(2κ°μ subplot)

## Result
- λ‘ λ¨λΈ λ¨λ‘ ν…μ¤νΈ λ°μ΄ν„°μ—μ„ Accuracyλ¥Ό κ³„μ‚°ν•μ—¬ μ¶λ ¥ν–λ‹¤.
  - `π² Random Forest μ •ν™•λ„: {rf_acc:.4f}`
  - `π€ Gradient Boosting μ •ν™•λ„: {gb_acc:.4f}`
- κ° λ¨λΈλ³„λ΅ μ¤‘μ” νΉμ„± Top-5λ¥Ό λ§‰λ€κ·Έλν”„λ΅ ν™•μΈν•μ—¬,
  - λ¨λΈμ— λ”°λΌ μ¤‘μ”ν•κ² ν‰κ°€ν•λ” νΉμ„±μ΄ λ‹¤λ¥Ό μ μμμ„ μ‹κ°μ μΌλ΅ λΉ„κµν–λ‹¤.
- κ²°κ³Όμ μΌλ΅ **μ„±λ¥(μ •ν™•λ„) λΉ„κµ + ν•΄μ„(μ¤‘μ” νΉμ„± λΉ„κµ)**λ¥Ό ν• λ²μ— μν–‰ν•λ” κΈ°λ³Έ μ‹¤ν— νμ΄ν”„λΌμΈμ„ μ™„μ„±ν–λ‹¤.
